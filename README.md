# ğŸ‘» PromptMate - Local AI Chat Companion

ğŸ‘» PromptMate is a lightweight Streamlit web app that provides a chat interface powered by Ollama's Mistral language model. It enables interactive conversations with a local AI assistant, customizable via system prompts and temperature settings.

## ğŸŒŸ Key Features

### ğŸ’¬ Core Capabilities
- **Local AI Chat**: Private conversations with Mistral model
- **Smart Context**: Maintains conversation history naturally
- **Customizable Personality**: Adjust system prompts to shape AI behavior
- **Creativity Control**: Fine-tune responses with temperature settings

### ğŸš€ Technical Advantages
- **100% Offline**: No internet required after setup
- **No API Keys**: Completely self-contained
- **Local Processing**: All inference happens on your machine
- **Lightweight**: Simple Streamlit interface

## âš¡ Quick Start

### 1. Install Ollama 
```bash
Download and install Ollama from https://ollama.com
```
### 2. Pull the model
```bash
ollama pull mistral  # Download the model (~4.1GB)
```
### 3. Run the app
```bash
streamlit run app.py
```


ğŸ› ï¸ How It Works
1. User Interaction
- Launch Streamlit interface
- Type messages in chat input
- Adjust settings via sidebar

2. Local AI Processing
   
![deepseek_mermaid_20250604_38a9df](https://github.com/user-attachments/assets/e1f0e6e0-16b8-4667-8e1d-b10ecd737de6)

3. Response Generation
- System prompt sets behavior context
- Temperature adjusts creativity
- Full conversation history maintained

### ğŸ“Š Example Session

![image](https://github.com/user-attachments/assets/e2a054cc-6347-4398-8ec8-d5ef31f52691)

###ğŸ›¡ï¸ Privacy & Security
- No data sent to the cloud â€” everything runs locally
- No API keys or external dependencies
- Perfect for sensitive or private chats

###ğŸ¤ Contribute
- Found a bug or want to add features? Pull requests and issues are welcome!

###ğŸ“œ License
- MIT License â€” free to use and modify






