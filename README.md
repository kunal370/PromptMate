# ğŸ‘» PromptMate - Local AI Chat Assistant

ğŸ‘» PromptMate is a sleek, Streamlit-based chat app powered by the Mistral model via the Ollama CLI. It runs completely offline on your local machine, giving you a fast, secure, and private AI chat experience â€” no API keys or internet required!


## Features

- âœ… Instant conversational AI powered by Ollamaâ€™s Mistral model
- ğŸ› ï¸ Customize the assistant with your own system prompt
- ğŸŒ¡ï¸ Control creativity and response style with adjustable temperature
- ğŸ’¬ Streamed real-time replies for smooth chatting
- â™»ï¸ Clear chat history anytime with one click
- ğŸ”’ Fully offline â€” your data never leaves your computer
- ğŸ¨ Clean, simple UI built with Streamlit

- ğŸ’¬ Chat with Mistral model locally
- âš™ï¸ Customizable system prompts
- ğŸŒ¡ï¸ Temperature control for response creativity
- ğŸ§¹ One-click chat history clearing
- ğŸš€ Streamed responses for natural interaction

Simple and clean chat interface using Streamlit's native chat components

Uses Ollama's Mistral model for generating AI responses locally

Customize system prompt to guide assistant behavior

Adjustable temperature setting for creativity control

Chat history maintained within the session

Clear chat button to reset conversation

# ğŸ‘» PromptMate - Local AI Chat Companion

**ğŸ› ï¸ PromptMate is a Streamlit-powered local AI chatbot** that leverages Ollama's Mistral model for completely offline, secure conversations. Get instant answers without compromising privacy or relying on external APIs.

![Demo Animation](https://via.placeholder.com/800x500.gif?text=PromptMate+Demo+Animation)

## ğŸŒŸ Key Features

### ğŸ’¬ Core Capabilities
- **Local AI Chat**: Private conversations with Mistral model
- **Smart Context**: Maintains conversation history naturally
- **Customizable Personality**: Adjust system prompts to shape AI behavior
- **Creativity Control**: Fine-tune responses with temperature settings

### ğŸš€ Technical Advantages
- **100% Offline**: No internet required after setup
- **No API Keys**: Completely self-contained
- **Local Processing**: All inference happens on your machine
- **Lightweight**: Simple Streamlit interface

## âš¡ Quick Start

### Prerequisites
```bash
ollama pull mistral  # Download the model (~4.1GB)


Usage
bash
ollama serve &  # Start in background
streamlit run app.py

ğŸ› ï¸ How It Works
User Interaction

Launch Streamlit interface

Type messages in chat input

Adjust settings via sidebar

Local AI Processing
![deepseek_mermaid_20250604_38a9df](https://github.com/user-attachments/assets/e1f0e6e0-16b8-4667-8e1d-b10ecd737de6)
Response Generation

System prompt sets behavior context

Temperature adjusts creativity

Full conversation history maintained

ğŸ“Š Example Session
![image](https://github.com/user-attachments/assets/e2a054cc-6347-4398-8ec8-d5ef31f52691)




